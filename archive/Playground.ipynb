{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c700b98d-6f28-4dae-90dd-ba81a97d257c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from accelerate import Accelerator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch import cuda, nn\n",
    "\n",
    "MAX_LENGTH = 80\n",
    "NUM_OF_OUTPUTS = 50\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "first_model_checkpoint = \"royweiss1/T5_FirstSentences\"\n",
    "first_model = AutoModelForSeq2SeqLM.from_pretrained(first_model_checkpoint)\n",
    "first_tokenizer = AutoTokenizer.from_pretrained(first_model_checkpoint)\n",
    "\n",
    "cuda.empty_cache()\n",
    "accelerator = Accelerator(cpu=False)\n",
    "print(\"-------Device:\", accelerator.device)\n",
    "first_model = first_model.to(accelerator.device)\n",
    "\n",
    "def generate_first(encodings):\n",
    "    \n",
    "    inputs = first_tokenizer(encodings, max_length=MAX_LENGTH, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    inputs = {k: v.to(accelerator.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Generate text using the model on the same device\n",
    "    outputs = first_model.generate(\n",
    "        **inputs,\n",
    "        max_length=MAX_LENGTH,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True,\n",
    "        no_repeat_ngram_size=2,\n",
    "        top_k=50,\n",
    "        num_beam_groups=16,\n",
    "        num_beams=NUM_OF_OUTPUTS,\n",
    "        diversity_penalty=0.8,\n",
    "        num_return_sequences=NUM_OF_OUTPUTS\n",
    "    )\n",
    "\n",
    "    sequences = outputs.sequences\n",
    "    sequence_scores = outputs.sequences_scores\n",
    "    \n",
    "    sorted_indices = sequence_scores.argsort(descending=True)\n",
    "\n",
    "    # Extract the sequences and scores based on the sorted indices\n",
    "    sorted_sequences = sequences[sorted_indices]\n",
    "\n",
    "    # Convert the sorted sequences to a readable format (e.g., string)\n",
    "    sorted_texts = [first_tokenizer.decode(seq, skip_special_tokens=True) for seq in sorted_sequences]\n",
    "\n",
    "    return sorted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af87ef27-72c8-451c-b8c9-4b4ab3feb61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7, 13, 3, 8, 9, 4, 11, 13, 5, 6, 36, 9, 5]\n"
     ]
    }
   ],
   "source": [
    "lst_of_lengths = [955, 971,985, 1011,1017,1033,1051,1059,1081,1107,1117,1129,1201,1219,1229] # TODO: fill\n",
    "\n",
    "def parse_packet_lengths(lengths):\n",
    "    token_lengths = []\n",
    "    for i in range(1, len(lengths)):\n",
    "        token_lengths.append((lengths[i] - lengths[i-1])//2)\n",
    "    return token_lengths\n",
    "        \n",
    "token_lens = parse_packet_lengths(lst_of_lengths)\n",
    "        \n",
    "print(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae368040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(lengths):\n",
    "    sentences = []\n",
    "    index = 0\n",
    "    tokens_in_streak = 0\n",
    "    while index < len(lengths):\n",
    "        if tokens_in_streak >= 10 and lengths[index] == 1:\n",
    "            if lengths[index-1] == 3:\n",
    "                sentences.append(lengths[:tokens_in_streak])\n",
    "                lengths = lengths[tokens_in_streak:]\n",
    "            elif lengths[index-1] == 1:\n",
    "                sentences.append(lengths[:tokens_in_streak-1])\n",
    "                lengths = lengths[tokens_in_streak-1:]\n",
    "                index -= 1\n",
    "            else:\n",
    "                sentences.append(lengths[:tokens_in_streak+1])\n",
    "                lengths = lengths[tokens_in_streak+1:]\n",
    "                index += 1\n",
    "            tokens_in_streak = 0\n",
    "        else:\n",
    "            index += 1\n",
    "            tokens_in_streak += 1\n",
    "    else:\n",
    "        if tokens_in_streak > 0:\n",
    "            sentences.append(lengths)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f79ac2b-3fcb-4d3a-a12e-6e33580622d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 0. Output: several recent advancements in machine learning and artificial intelligence that could be a game-changing tool\n",
      "Rank: 1. Output: several recent developments in machine learning and artificial intelligence that could be of interest to\n",
      "Rank: 2. Output: park managers collaborate on several projects for maximizing recreational play value in a specific area.\n",
      "Rank: 3. Output: firms employ standardized or uniform policies for addressing intersectionality issues in a specific area.\n",
      "Rank: 4. Output: ertiveness allows participants to express emotions and experience interactions with their co-workers more\n",
      "Rank: 5. Output: ers utilize cryptography to protect personal and financial transactions from fraud or ID theft.\n",
      "Rank: 6. Output: land restoration efforts at Niagara Falls are constantly integrating with those of the national park\n",
      "Rank: 7. Output: ethical issues pertaining to genetic research are considered intersectionality since it is research that\n",
      "Rank: 8. Output: could be genetic research on African elephants for behavioral applications like grooming or sex education.\n",
      "Rank: 9. Output: Affordable Care Act imposed stricter penalties for healthcare institutions that violated it, hospitals have\n",
      "Rank: 10. Output: limited global implications to promote cultural and historical preservation from Tokyo to Xi'an province only\n",
      "Rank: 11. Output: several latest advancements in medical research and technology specifically made based on a research study\n",
      "Rank: 12. Output: could be genetic research on African elephants for behavioral applications like grooming or sex training.\n",
      "Rank: 13. Output: ing common perspectives or ethical concerns can facilitate constructive dialogue in a conflict zone\n",
      "Rank: 14. Output: several future developments in machine learning and artificial intelligence that could be a game-changing tool.\n",
      "Rank: 15. Output: climate technologies in Central America are undergoing advancements that focus on decarbonization\n",
      "Rank: 16. Output: require travel restrictions or special permits for commercial applications when using an RV-equipped home\n",
      "Rank: 17. Output: several recent advancements in machine learning and artificial intelligence that could be an influencing factor\n",
      "Rank: 18. Output: factors contributing to climate patterns and ecological disturbances vary based on the location used\n",
      "Rank: 19. Output: firms employ professional geothermal services for commercial applications when there is no rainfall data\n",
      "Rank: 20. Output: ing common perspectives or ethical concerns can facilitate constructive dialogue in a business plan\n",
      "Rank: 21. Output: firms employ standardized or uniform policies for addressing intersectionality issues in a business setting.\n",
      "Rank: 22. Output: factors differ specifically in shaping cultural and linguistic interactions with China. On one hand,\n",
      "Rank: 23. Output: land restoration efforts at Niagara Falls are constantly integrating with those of the National Parks\n",
      "Rank: 24. Output: parent implications of genetic research and artificial intelligence will focus on the following areas:\n",
      "Rank: 25. Output: limited global implications to promote cultural and historical preservation from Tokyo to Xi'an province with\n",
      "Rank: 26. Output: factors contributing to climate patterns and ecological disturbances vary based on the location they\n",
      "Rank: 27. Output: several future developments in machine learning and artificial intelligence that could be a game-changing tool\n",
      "Rank: 28. Output: utilize mobile applications to develop personal and contextual interactions with users in a specific area.\n",
      "Rank: 29. Output: are several recent advancements in machine learning and artificial intelligence that could be an influencing factor\n",
      "Rank: 30. Output: parent implications of genetic research and artificial intelligence will focus on the following ways:\n",
      "Rank: 31. Output: park managers collaborate on several projects for maximizing recreational play value in a specific park.\n",
      "Rank: 32. Output: ethical issues pertaining to genetic research are considered intersectionality since it is commonly used\n",
      "Rank: 33. Output: firms employ professional geothermal services for commercial applications when there is no rainfall fall\n",
      "Rank: 34. Output: climate technologies in Central America are undergoing advancements that serve as a powerful tool\n",
      "Rank: 35. Output: several latest advancements in medical research and technology specifically made based on a research team\n",
      "Rank: 36. Output: factors differ specifically in shaping cultural and linguistic interactions with China. Cultural Differences:\n",
      "Rank: 37. Output: Affordable Care Act imposed stricter penalties for healthcare institutions that violated it, hospitals must\n",
      "Rank: 38. Output: ertiveness allows participants to express emotions and experience interactions with their co-workers with\n",
      "Rank: 39. Output: several latest developments in medical research and technology specifically made known by the National Heart\n",
      "Rank: 40. Output: ers utilize cryptography to protect personal and financial transactions from fraud or cyberattacks.\n",
      "Rank: 41. Output: several latest developments in medical research and technology specifically made known by the National Parks\n",
      "Rank: 42. Output: there are several recent advancements in machine learning and artificial intelligence that could be of interest to\n",
      "Rank: 43. Output: there are several recent advancements in machine learning and artificial intelligence that could be of interest here\n",
      "Rank: 44. Output: are several recent advancements in machine learning and artificial intelligence that could be put to practical use\n",
      "Rank: 45. Output: QL has several unique capabilities to support multiple I/O operations concurrently with those of JSON-P protocol calls\n",
      "Rank: 46. Output: several recent advancements in machine learning and artificial intelligence that could be an empowering tool\n",
      "Rank: 47. Output: QL has several unique capabilities to support multiple I/O operations concurrently with those of JSON-P serial data\n",
      "Rank: 48. Output: utilize mobile applications to develop personal and contextual interactions with users in a personal life\n",
      "Rank: 49. Output: require travel restrictions or special permits for commercial applications when using an RV-equipped camp\n"
     ]
    }
   ],
   "source": [
    "def make_input(lst_lengths):\n",
    "    lst_str = \" \".join([f\"_{i}\" for i in lst_lengths])\n",
    "    return f\"Translate the Special Tokens to English. \\nSpecial Tokens:{lst_str}\"\n",
    "\n",
    "# Decrypt model message\n",
    "token_lens = heuristic(token_lens)[0] # take the first sentence based on the heuristic\n",
    "outputs = generate_first([make_input(token_lens)]) # output is sorted by the model's confidence!!!!\n",
    "\n",
    "for rank, output in enumerate(outputs):\n",
    "    print(f\"Rank: {rank+1}. Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentence_transformers = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v1')\n",
    "model_sentence_transformers = model_sentence_transformers.to(accelerator.device) \n",
    "def compute_metrics(reference_sentence, sentence_to_compare):\n",
    "    embed_pred = model_sentence_transformers.encode([sentence_to_compare], convert_to_tensor=True)\n",
    "    embed_reference = model_sentence_transformers.encode([reference_sentence], convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    sen_trans_score = cos(embed_pred, embed_reference)\n",
    "    cosine_score = tuple(sen_trans_score.detach().cpu().numpy())\n",
    "    return float(f\"{cosine_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb743a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_LLM_Response = \"FILL HERE\"\n",
    "for rank, output in enumerate(outputs):\n",
    "    print(f\"Rank: {rank+1}. Phi Score: {compute_metrics(Original_LLM_Response, output)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
